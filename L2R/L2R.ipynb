{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Rank\n",
    "\n",
    "## Feature extraction\n",
    "\n",
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pid                                            passage\n",
      "0              0  The presence of communication amid scientific ...\n",
      "1              1  The Manhattan Project and its atomic bomb help...\n",
      "2              2  Essay on The Manhattan Project - The Manhattan...\n",
      "3              3  The Manhattan Project was the name for a proje...\n",
      "4              4  versions of each volume as well as complementa...\n",
      "...          ...                                                ...\n",
      "8841818  8841818  When metal salts emit short wavelengths of vis...\n",
      "8841819  8841819  Thousands of people across the United States w...\n",
      "8841820  8841820  The recipe that creates blue, for example, inc...\n",
      "8841821  8841821  On Independence Days of yore, old-timey crowds...\n",
      "8841822  8841822  View full size image. Behind the scenes of the...\n",
      "\n",
      "[8841823 rows x 2 columns]\n",
      "            qid                                           query\n",
      "0        121352                                  define extreme\n",
      "1        634306        what does chattel mean on credit history\n",
      "2        920825         what was the great leap forward brainly\n",
      "3        510633             tattoo fixers how much does it cost\n",
      "4        737889               what is decentralization process.\n",
      "...         ...                                             ...\n",
      "808726   633855          what does canada post regulations mean\n",
      "808727  1059728                         wholesale lularoe price\n",
      "808728   210839                   how can i watch the day after\n",
      "808729   908165           what to use instead of pgp in windows\n",
      "808730    50393  benefits of boiling lemons and drinking juice.\n",
      "\n",
      "[808731 rows x 2 columns]\n",
      "            qid  Q0    docid  rating\n",
      "0       1185869   0        0       1\n",
      "1       1185868   0       16       1\n",
      "2        597651   0       49       1\n",
      "3        403613   0       60       1\n",
      "4       1183785   0      389       1\n",
      "...         ...  ..      ...     ...\n",
      "532756    19285   0  8841362       1\n",
      "532757   558837   0  4989159       1\n",
      "532758   559149   0  8841547       1\n",
      "532759   706678   0  8841643       1\n",
      "532760   405466   0  8841735       1\n",
      "\n",
      "[532761 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyserini.index import IndexReader\n",
    "\n",
    "# Load collection\n",
    "passages = pd.read_csv('collections/msmarco-passage/collectionandqueries/collection.tsv', sep = '\\t', names=['pid', 'passage'])\n",
    "\n",
    "# Load training data\n",
    "queries_train = pd.read_csv('collections/msmarco-passage/collectionandqueries/queries.train.tsv', sep = '\\t', names=['qid', 'query'])\n",
    "qrels_train = pd.read_csv('collections/msmarco-passage/collectionandqueries/qrels.train.tsv', sep = '\\t', names=['qid', 'Q0', 'docid', 'rating'])\n",
    "\n",
    "print(passages)\n",
    "print(queries_train)\n",
    "print(qrels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to initialize pre-built index msmarco-passage.\n",
      "/Users/jessie/.cache/pyserini/indexes/index-msmarco-passage-20201117-f87c94.1efad4f1ae6a77e235042eff4be1612d already exists, skipping download.\n",
      "Initializing msmarco-passage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18292/532761 [05:06<2:05:07, 68.53it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "  5%|▍         | 25651/532761 [07:02<2:01:02, 69.83it/s] <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "  6%|▌         | 31139/532761 [08:47<2:47:54, 49.79it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "  7%|▋         | 37889/532761 [10:31<2:23:15, 57.57it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "  8%|▊         | 44509/532761 [12:16<1:53:51, 71.47it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 10%|█         | 53993/532761 [14:44<2:10:44, 61.03it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 10%|█         | 55445/532761 [15:06<2:08:59, 61.67it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 12%|█▏        | 64645/532761 [17:44<2:43:42, 47.66it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 13%|█▎        | 68623/532761 [19:20<2:47:43, 46.12it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 19%|█▊        | 99047/532761 [32:05<4:57:56, 24.26it/s] <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 19%|█▉        | 102158/532761 [33:34<2:39:05, 45.11it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 20%|█▉        | 105306/532761 [35:05<3:21:56, 35.28it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 22%|██▏       | 114813/532761 [38:48<2:25:16, 47.95it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 24%|██▍       | 126576/532761 [43:33<1:44:45, 64.63it/s] <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 27%|██▋       | 143429/532761 [47:39<1:21:10, 79.94it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 28%|██▊       | 151111/532761 [49:33<1:28:41, 71.72it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 36%|███▌      | 192231/532761 [58:19<1:11:35, 79.28it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 39%|███▉      | 207539/532761 [1:01:43<1:07:41, 80.08it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 40%|████      | 213655/532761 [1:03:01<1:09:16, 76.78it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 42%|████▏     | 222511/532761 [1:04:54<1:05:47, 78.60it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 45%|████▌     | 242120/532761 [1:09:07<1:01:21, 78.94it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 47%|████▋     | 249114/532761 [1:10:36<59:01, 80.09it/s]  <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 49%|████▉     | 260749/532761 [1:13:04<55:54, 81.09it/s]  <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 49%|████▉     | 260878/532761 [1:13:05<57:44, 78.48it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 54%|█████▍    | 289957/532761 [1:19:16<54:50, 73.80it/s]  <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 57%|█████▋    | 304296/532761 [1:22:18<48:18, 78.82it/s]  <ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 58%|█████▊    | 310937/532761 [1:23:42<46:26, 79.61it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 58%|█████▊    | 310981/532761 [1:23:43<51:59, 71.09it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 63%|██████▎   | 337858/532761 [1:29:22<40:20, 80.53it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 69%|██████▉   | 367475/532761 [1:35:38<34:45, 79.27it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 70%|███████   | 375287/532761 [1:37:17<32:34, 80.56it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 72%|███████▏  | 384673/532761 [1:39:16<30:20, 81.36it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 72%|███████▏  | 384682/532761 [1:39:16<31:04, 79.43it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 74%|███████▍  | 396054/532761 [1:41:41<29:03, 78.40it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 76%|███████▌  | 404790/532761 [1:43:32<27:20, 78.02it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 76%|███████▋  | 406808/532761 [1:43:58<25:48, 81.32it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 78%|███████▊  | 414566/532761 [1:45:44<27:36, 71.36it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 82%|████████▏ | 438067/532761 [1:51:16<21:38, 72.93it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 88%|████████▊ | 467760/532761 [1:58:03<13:49, 78.39it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 88%|████████▊ | 470634/532761 [1:58:40<12:50, 80.68it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 89%|████████▉ | 473178/532761 [1:59:12<12:27, 79.67it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 89%|████████▉ | 474899/532761 [1:59:35<12:17, 78.50it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 483775/532761 [2:01:26<09:57, 82.04it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 93%|█████████▎| 495455/532761 [2:04:11<08:34, 72.50it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 93%|█████████▎| 496517/532761 [2:04:25<08:04, 74.75it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 96%|█████████▋| 512977/532761 [2:07:58<04:14, 77.60it/s]<ipython-input-2-c870f1d99fb6>:34: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "100%|██████████| 532761/532761 [2:12:38<00:00, 66.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create index reader to analyze terms and compute metrics\n",
    "index_reader = IndexReader('indexes/collection_jsonl')\n",
    "\n",
    "# List to store features calculated from the training data\n",
    "training_data = []\n",
    "\n",
    "# Going through all query-document pairs\n",
    "for index in tqdm(range(len(qrels_train))):\n",
    "    row = qrels_train.loc[index]\n",
    "    \n",
    "    # Identifying relevant query and passage/document\n",
    "    query = queries_train[queries_train['qid'] == row['qid']]['query'].values[0]\n",
    "    passage = passages[passages['pid'] == row['docid']]['passage'].values[0]\n",
    "    \n",
    "    rating = row['rating']\n",
    "    \n",
    "    # Computing BM25\n",
    "    bm25_score = index_reader.compute_query_document_score(str(row['docid']), query)\n",
    "    \n",
    "    # Computing passage length\n",
    "    passage_length = len(passage)\n",
    "\n",
    "    # Initializing c, df, cf, idf, and c*idf\n",
    "    c = 0\n",
    "    df = 0\n",
    "    cf = 0\n",
    "    idf = 0\n",
    "    c_idf = 0\n",
    "    C = len(passages)\n",
    "    \n",
    "    # Get analyzed passage\n",
    "    passage_analyzed = index_reader.analyze(passage)\n",
    "    \n",
    "    # Go through analyzed terms in the query\n",
    "    for term in index_reader.analyze(query):\n",
    "        # If there are no analyzed terms, skip the term\n",
    "        if index_reader.analyze(term) == []:\n",
    "            continue\n",
    "        else:\n",
    "            # Compute each of the metrics as specified by LETOR\n",
    "            c += passage_analyzed.count(term)\n",
    "            df_temp, cf_temp = index_reader.get_term_counts(term) \n",
    "            df += df_temp\n",
    "            cf += cf_temp\n",
    "            idf += np.log((C - df + 0.5) / (df + 0.5))\n",
    "\n",
    "            c_idf += c * idf\n",
    "    \n",
    "    # Add relevant data to list\n",
    "    temp = [row['qid'], row['docid'], row['rating'], bm25_score, passage_length, c, df, cf, idf, c_idf]\n",
    "    training_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            qid    docid  rating       bm25  passage_length   c       df  \\\n",
      "0       1185869        0       1  11.560829             325   5   797858   \n",
      "1       1185868       16       1  20.567997             306   9   917868   \n",
      "2        597651       49       1  11.347543             305   6   718082   \n",
      "3        403613       60       1  13.854973             521   7   200763   \n",
      "4       1183785      389       1  10.219151             319   3   390237   \n",
      "...         ...      ...     ...        ...             ...  ..      ...   \n",
      "532756    19285  8841362       1   8.897675             304   2   209748   \n",
      "532757   558837  4989159       1   3.825954             297   3   612669   \n",
      "532758   559149  8841547       1  13.113671             214   4  1068484   \n",
      "532759   706678  8841643       1   7.690524             149   1   543276   \n",
      "532760   405466  8841735       1  10.627259             798  13   155130   \n",
      "\n",
      "             cf        idf        c_idf  \n",
      "0        983404  15.112933   173.856118  \n",
      "1       1175894  44.489958  2765.200357  \n",
      "2        959345  10.137694    94.404182  \n",
      "3        334483  30.979131   551.382704  \n",
      "4        561290  17.817594    68.195023  \n",
      "...         ...        ...          ...  \n",
      "532756   250468  16.142798    57.136530  \n",
      "532757   778692   7.931131    39.793947  \n",
      "532758  1330541  11.752486   105.114842  \n",
      "532759   664380   5.452472     5.452472  \n",
      "532760   269447  13.324790   326.233462  \n",
      "\n",
      "[532712 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform data into dataframe\n",
    "training_data = pd.DataFrame(training_data, columns=['qid', 'docid', 'rating', 'bm25', \\\n",
    "                                                     'passage_length', 'c', 'df', 'cf', \\\n",
    "                                                     'idf', 'c_idf']).dropna()\n",
    "\n",
    "# Save to csv in case the kernel is stopped during experiments\n",
    "training_data.to_csv('training_data.csv')\n",
    "\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [5:02:04<00:00,  1.81s/it]  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# List to store features calculated from nonrelevant pairs in the training data\n",
    "training_data_nonrelevant = []\n",
    "\n",
    "# Go through a sample of 10,000 query-document pairs from the training data\n",
    "for index in tqdm(random.sample(range(len(qrels_train)), 10000)):\n",
    "    row = qrels_train.loc[index]\n",
    "    \n",
    "    # Identifying relevant query\n",
    "    query = queries_train[queries_train['qid'] == row['qid']]['query'].values[0]\n",
    "    \n",
    "    # Sample a docid that is not the current docid\n",
    "    docid = passages[passages['pid'] != row['docid']]['pid'].sample().values[0]\n",
    "    \n",
    "    # Identify 'irrelevant' passage\n",
    "    passage = passages[passages['pid'] == docid]['passage'].values[0]\n",
    "    \n",
    "    rating = row['rating']\n",
    "    \n",
    "    # Same code as computing metrics for relevant pairs\n",
    "    bm25_score = index_reader.compute_query_document_score(str(docid), query)\n",
    "    \n",
    "    passage_length = len(passage)\n",
    "\n",
    "    c = 0\n",
    "    df = 0\n",
    "    cf = 0\n",
    "    idf = 0\n",
    "    c_idf = 0\n",
    "    C = len(passages)\n",
    "    passage_analyzed = index_reader.analyze(passage)\n",
    "    for term in index_reader.analyze(query):\n",
    "        if index_reader.analyze(term) == []:\n",
    "            continue\n",
    "        else:\n",
    "            c += passage_analyzed.count(term)\n",
    "            df_temp, cf_temp = index_reader.get_term_counts(term) \n",
    "            df += df_temp\n",
    "            cf += cf_temp\n",
    "            idf += np.log((C - df + 0.5) / (df + 0.5))\n",
    "\n",
    "            c_idf += c * idf\n",
    "    \n",
    "    temp = [row['qid'], docid, 0, bm25_score, passage_length, c, df, cf, idf, c_idf]\n",
    "    training_data_nonrelevant.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          qid    docid  rating      bm25  passage_length  c       df       cf  \\\n",
      "0      539478  2693464       0  0.000000             258  0    91835   113542   \n",
      "1      400705  7629915       0  0.000000             205  0   150809   186927   \n",
      "2        2797  3365674       0  0.000000             282  0   622866   810154   \n",
      "3      734390  6235369       0  0.000000             505  0   780361   969702   \n",
      "4      345809   971793       0  0.000000             296  0   756389   955734   \n",
      "...       ...      ...     ...       ...             ... ..      ...      ...   \n",
      "9995    92552  5884425       0  0.000000             268  0   221142   264779   \n",
      "9996   435696  2716350       0  2.086764             304  1   221593   267426   \n",
      "9997  1181703  8602111       0  0.000000             321  0   486729   732203   \n",
      "9998  1173262  3786944       0  0.000000             737  0   122353   181461   \n",
      "9999   650309  7430049       0  0.000000             334  0  1645114  2377775   \n",
      "\n",
      "            idf      c_idf  \n",
      "0     19.629243   0.000000  \n",
      "1     17.536045   0.000000  \n",
      "2     15.544755   0.000000  \n",
      "3      7.419494   0.000000  \n",
      "4      9.926725   0.000000  \n",
      "...         ...        ...  \n",
      "9995  19.256276   0.000000  \n",
      "9996  19.153344  19.153344  \n",
      "9997  20.982625   0.000000  \n",
      "9998  13.853809   0.000000  \n",
      "9999  12.330284   0.000000  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform data into dataframe\n",
    "training_data_nonrelevant = pd.DataFrame(training_data_nonrelevant, columns=['qid', 'docid', 'rating', 'bm25', \\\n",
    "                                                                             'passage_length', 'c', 'df', 'cf', \\\n",
    "                                                                             'idf', 'c_idf']).dropna()\n",
    "# Save to csv in case the kernel is stopped during experiments\n",
    "training_data_nonrelevant.to_csv('training_data_nonrelevant.csv')\n",
    "print(training_data_nonrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2318.29it/s]\n",
      "100%|██████████| 10000/10000 [00:03<00:00, 2747.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write data to a file in the LETOR format\n",
    "with open('training_data.txt', 'w') as file:\n",
    "    # Sample part of the relevant query document pair features\n",
    "    sample = training_data.sample(10000)\n",
    "    # Go through sample and write each record to a text file\n",
    "    for index in tqdm(range(len(sample))):\n",
    "        row = sample.iloc[index]\n",
    "        file.write('{} qid:{} 1:{} 2:{} 3:{} 4:{} 5:{} 6:{} 7:{} # docid = {} \\n'.format(int(row['rating']), int(row['qid']), \\\n",
    "                                                                         row['bm25'], row['passage_length'], \\\n",
    "                                                                        row['c'], row['df'], row['cf'], \\\n",
    "                                                                        row['idf'], row['c_idf'], int(row['docid'])))\n",
    "    # Go through nonrelevant query document pair features and write each record to a text file\n",
    "    for index in tqdm(range(len(training_data_nonrelevant))):\n",
    "        row = training_data_nonrelevant.iloc[index]\n",
    "        file.write('{} qid:{} 1:{} 2:{} 3:{} 4:{} 5:{} 6:{} 7:{} # docid = {} \\n'.format(int(row['rating']), int(row['qid']), \\\n",
    "                                                                        row['bm25'], row['passage_length'], \\\n",
    "                                                                        row['c'], row['df'], row['cf'], \\\n",
    "                                                                        row['idf'], row['c_idf'], int(row['docid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          qid                                          query\n",
      "0     1048585                   what is paula deen's brother\n",
      "1           2                       Androgen receptor define\n",
      "2      524332  treating tension headaches without medication\n",
      "3     1048642                            what is paranoid sc\n",
      "4      524447            treatment of varicose veins in legs\n",
      "...       ...                                            ...\n",
      "6975   734979                           what is coronary cta\n",
      "6976   524166              transportation to us bank stadium\n",
      "6977   968921                 where did last names originate\n",
      "6978   786375                 what is preoperative clearance\n",
      "6979  1048565                  who plays sebastian michaelis\n",
      "\n",
      "[6980 rows x 2 columns]\n",
      "         qid  Q0    docid  rating\n",
      "0     300674   0  7067032       1\n",
      "1     125705   0  7067056       1\n",
      "2      94798   0  7067181       1\n",
      "3       9083   0  7067274       1\n",
      "4     174249   0  7067348       1\n",
      "...      ...  ..      ...     ...\n",
      "7432  147073   0  8008770       1\n",
      "7433  243761   0  8008787       1\n",
      "7434  162662   0  8008977       1\n",
      "7435  247194   0  8009319       1\n",
      "7436  195199   0  8009377       1\n",
      "\n",
      "[7437 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "queries_val = pd.read_csv('collections/msmarco-passage/collectionandqueries/queries.dev.small.tsv', sep = '\\t', names=['qid', 'query'])\n",
    "qrels_val = pd.read_csv('collections/msmarco-passage/collectionandqueries/qrels.dev.small.tsv', sep = '\\t', names=['qid', 'Q0', 'docid', 'rating'])\n",
    "\n",
    "print(queries_val)\n",
    "print(qrels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2132/7437 [00:31<01:30, 58.77it/s]<ipython-input-9-867129774ef1>:28: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      " 53%|█████▎    | 3928/7437 [00:55<00:46, 75.94it/s]<ipython-input-9-867129774ef1>:28: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "100%|██████████| 7437/7437 [01:46<00:00, 69.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Same code as for the relevant training query-document pairs\n",
    "validation_data = []\n",
    "\n",
    "for index in tqdm(range(len(qrels_val))):\n",
    "    row = qrels_val.loc[index]\n",
    "    query = queries_val[queries_val['qid'] == row['qid']]['query'].values[0]\n",
    "    passage = passages[passages['pid'] == row['docid']]['passage'].values[0]\n",
    "    rating = row['rating']\n",
    "    \n",
    "    bm25_score = index_reader.compute_query_document_score(str(row['docid']), query)\n",
    "    \n",
    "    passage_length = len(passage)\n",
    "\n",
    "    c = 0\n",
    "    df = 0\n",
    "    cf = 0\n",
    "    idf = 0\n",
    "    c_idf = 0\n",
    "    C = len(passages)\n",
    "    passage_analyzed = index_reader.analyze(passage)\n",
    "    for term in index_reader.analyze(query):\n",
    "        if index_reader.analyze(term) == []:\n",
    "            continue\n",
    "        else:\n",
    "            c += passage_analyzed.count(term)\n",
    "            df_temp, cf_temp = index_reader.get_term_counts(term) \n",
    "            df += df_temp\n",
    "            cf += cf_temp\n",
    "            idf += np.log((C - df + 0.5) / (df + 0.5))\n",
    "\n",
    "            c_idf += c * idf\n",
    "    \n",
    "    temp = [row['qid'], row['docid'], row['rating'], bm25_score, passage_length, c, df, cf, idf, c_idf]\n",
    "    validation_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         qid    docid  rating       bm25  passage_length   c       df  \\\n",
      "0     300674  7067032       1  24.918810             324   9  2081477   \n",
      "1     125705  7067056       1   3.744147             186   4   211104   \n",
      "2      94798  7067181       1  13.672122             542   9   135438   \n",
      "3       9083  7067274       1  11.293467             169   4   329167   \n",
      "4     174249  7067348       1   8.314486             630  16  2118995   \n",
      "...      ...      ...     ...        ...             ...  ..      ...   \n",
      "7432  147073  8008770       1  11.880719             257   8  1126133   \n",
      "7433  243761  8008787       1  12.142422             497   7  1083447   \n",
      "7434  162662  8008977       1  17.052584             220   4  2425838   \n",
      "7435  247194  8009319       1   8.106571             262   3  3267541   \n",
      "7436  195199  8009377       1   5.757708             233   1   390524   \n",
      "\n",
      "           cf        idf       c_idf  \n",
      "0     2715181  14.770192  395.896149  \n",
      "1      248706   8.136258   32.545033  \n",
      "2      223271  12.543782  192.563440  \n",
      "3      391382  14.462967  110.908275  \n",
      "4     3758048  21.800744  781.817775  \n",
      "...       ...        ...         ...  \n",
      "7432  1405171  11.612517  147.030217  \n",
      "7433  1348790  13.311533  188.913901  \n",
      "7434  4369426  17.639658  233.012213  \n",
      "7435  5476419   8.283072   40.347107  \n",
      "7436   561754  13.397952   23.721319  \n",
      "\n",
      "[7435 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform data into dataframe\n",
    "validation_data = pd.DataFrame(validation_data, columns=['qid', 'docid', 'rating', 'bm25', \\\n",
    "                                                         'passage_length', 'c', 'df', 'cf', \\\n",
    "                                                         'idf', 'c_idf']).dropna()\n",
    "\n",
    "# Save to csv in case the kernel is stopped during experiments\n",
    "validation_data.to_csv('validation_data.csv')\n",
    "print(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 651/1000 [23:41<13:36,  2.34s/it]  <ipython-input-56-7b30b1618ca8>:29: RuntimeWarning: invalid value encountered in log\n",
      "  idf += np.log((C - df + 0.5) / (df + 0.5))\n",
      "100%|██████████| 1000/1000 [42:45<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Same code as for the non-relevant training query-document pairs\n",
    "validation_data_nonrelevant = []\n",
    "\n",
    "for index in tqdm(random.sample(range(len(qrels_val)), 1000)):\n",
    "    row = qrels_val.loc[index]\n",
    "    query = queries_val[queries_val['qid'] == row['qid']]['query'].values[0]\n",
    "    docid = passages[passages['pid'] != row['docid']]['pid'].sample().values[0]\n",
    "    passage = passages[passages['pid'] == docid]['passage'].values[0]\n",
    "    rating = row['rating']\n",
    "    \n",
    "    bm25_score = index_reader.compute_query_document_score(str(docid), query)\n",
    "    \n",
    "    passage_length = len(passage)\n",
    "\n",
    "    c = 0\n",
    "    df = 0\n",
    "    cf = 0\n",
    "    idf = 0\n",
    "    c_idf = 0\n",
    "    C = len(passages)\n",
    "    passage_analyzed = index_reader.analyze(passage)\n",
    "    for term in index_reader.analyze(query):\n",
    "        if index_reader.analyze(term) == []:\n",
    "            continue\n",
    "        else:\n",
    "            c += passage_analyzed.count(term)\n",
    "            df_temp, cf_temp = index_reader.get_term_counts(term) \n",
    "            df += df_temp\n",
    "            cf += cf_temp\n",
    "            idf += np.log((C - df + 0.5) / (df + 0.5))\n",
    "\n",
    "            c_idf += c * idf\n",
    "    \n",
    "    temp = [row['qid'], docid, 0, bm25_score, passage_length, c, df, cf, idf, c_idf]\n",
    "    validation_data_nonrelevant.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         qid    docid  rating  bm25  passage_length  c       df       cf  \\\n",
      "0      27743  4682722       0   0.0             600  0   529555   788281   \n",
      "1     518675  1030433       0   0.0             242  0   350389   501527   \n",
      "2     727765  3245041       0   0.0             290  0   861528  1071565   \n",
      "3    1096619  7465244       0   0.0             293  0  1075196  1341418   \n",
      "4    1095928  7857386       0   0.0             235  0   953099  1231183   \n",
      "..       ...      ...     ...   ...             ... ..      ...      ...   \n",
      "994   988954  3187724       0   0.0             261  0   547616   674387   \n",
      "995   402427  6425929       0   0.0             265  0   224504   288905   \n",
      "996  1046475   169071       0   0.0             102  0   554641   679486   \n",
      "997   789997  6375925       0   0.0             259  0  1320154  1852520   \n",
      "998  1080968  6683466       0   0.0             259  0   528991   777616   \n",
      "\n",
      "           idf  c_idf  \n",
      "0    19.183001    0.0  \n",
      "1    20.578482    0.0  \n",
      "2    10.212658    0.0  \n",
      "3    12.713720    0.0  \n",
      "4     9.320797    0.0  \n",
      "..         ...    ...  \n",
      "994  11.015316    0.0  \n",
      "995  10.949132    0.0  \n",
      "996  10.839552    0.0  \n",
      "997  11.132881    0.0  \n",
      "998  15.678162    0.0  \n",
      "\n",
      "[999 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform data into dataframe\n",
    "validation_data_nonrelevant = pd.DataFrame(validation_data_nonrelevant, columns=['qid', 'docid', 'rating', \\\n",
    "                                                                                 'bm25', 'passage_length', \\\n",
    "                                                                                 'c', 'df', 'cf', 'idf', \\\n",
    "                                                                                 'c_idf']).dropna()\n",
    "# Save to csv in case the kernel is stopped during experiments\n",
    "validation_data_nonrelevant.to_csv('validation_data_nonrelevant.csv')\n",
    "print(validation_data_nonrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1064.83it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 1213.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Writing data to LETOR format, same code as for training data\n",
    "with open('validation_data.txt', 'w') as file:\n",
    "    sample = validation_data.sample(1000)\n",
    "    for index in tqdm(range(len(sample))):\n",
    "        row = sample.iloc[index]\n",
    "        file.write('{} qid:{} 1:{} 2:{} 3:{} 4:{} 5:{} 6:{} 7:{} # docid = {} \\n'.format(int(row['rating']), int(row['qid']), \\\n",
    "                                                                         row['bm25'], row['passage_length'], \\\n",
    "                                                                        row['c'], row['df'], row['cf'], \\\n",
    "                                                                        row['idf'], row['c_idf'], int(row['docid'])))\n",
    "    for index in tqdm(range(len(validation_data_nonrelevant))):\n",
    "        row = validation_data_nonrelevant.iloc[index]\n",
    "        file.write('{} qid:{} 1:{} 2:{} 3:{} 4:{} 5:{} 6:{} 7:{} # docid = {} \\n'.format(int(row['rating']), int(row['qid']), \\\n",
    "                                                                        row['bm25'], row['passage_length'], \\\n",
    "                                                                        row['c'], row['df'], row['cf'], \\\n",
    "                                                                        row['idf'], row['c_idf'], int(row['docid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         qid                                              query\n",
      "0    1108939                  what slows down the flow of blood\n",
      "1    1112389            what is the county for grand rapids, mn\n",
      "2     792752                                     what is ruclip\n",
      "3    1119729  what do you do when you have a nosebleed from ...\n",
      "4    1105095                  where is sugar lake lodge located\n",
      "..       ...                                                ...\n",
      "195   146187  difference between a mcdouble and a double che...\n",
      "196   634428                           what does chs stand for?\n",
      "197  1121986     what are the effects of having low blood sugar\n",
      "198   321441                 how much is a us postal stamp cost\n",
      "199   532603                   university of dubuque enrollment\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "          qid  Q0    docid  rating\n",
      "0       19335  Q0  1017759       0\n",
      "1       19335  Q0  1082489       0\n",
      "2       19335  Q0   109063       0\n",
      "3       19335  Q0  1160863       0\n",
      "4       19335  Q0  1160871       0\n",
      "...       ...  ..      ...     ...\n",
      "9255  1133167  Q0  8839920       2\n",
      "9256  1133167  Q0  8839922       2\n",
      "9257  1133167  Q0   944810       0\n",
      "9258  1133167  Q0   949411       0\n",
      "9259  1133167  Q0   977421       0\n",
      "\n",
      "[9260 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load testing data\n",
    "queries_test = pd.read_csv('collections/msmarco-passage/msmarco-test2019-queries.tsv', sep = '\\t', names=['qid', 'query'])\n",
    "qrels_test = pd.read_csv('collections/msmarco-passage/2019qrels-pass.txt', sep = ' ', names=['qid', 'Q0', 'docid', 'rating'])\n",
    "\n",
    "print(queries_test)\n",
    "print(qrels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9260/9260 [02:25<00:00, 63.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Same code as for the relevant training query-document pairs\n",
    "testing_data = []\n",
    "\n",
    "for index in tqdm(range(len(qrels_test))):\n",
    "    row = qrels_test.loc[index]\n",
    "    query = queries_test[queries_test['qid'] == row['qid']]['query'].values[0]\n",
    "    passage = passages[passages['pid'] == row['docid']]['passage'].values[0]\n",
    "    rating = row['rating']\n",
    "    \n",
    "    bm25_score = index_reader.compute_query_document_score(str(row['docid']), query)\n",
    "    \n",
    "    passage_length = len(passage)\n",
    "\n",
    "    c = 0\n",
    "    df = 0\n",
    "    cf = 0\n",
    "    idf = 0\n",
    "    c_idf = 0\n",
    "    C = len(passages)\n",
    "    passage_analyzed = index_reader.analyze(passage)\n",
    "    for term in index_reader.analyze(query):\n",
    "        if index_reader.analyze(term) == []:\n",
    "            continue\n",
    "        else:\n",
    "            c += passage_analyzed.count(term)\n",
    "            df_temp, cf_temp = index_reader.get_term_counts(term) \n",
    "            df += df_temp\n",
    "            cf += cf_temp\n",
    "            idf += np.log((C - df + 0.5) / (df + 0.5))\n",
    "\n",
    "            c_idf += c * idf\n",
    "    \n",
    "    temp = [row['qid'], row['docid'], row['rating'], bm25_score, passage_length, c, df, cf, idf, c_idf]\n",
    "    testing_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          qid    docid  rating      bm25  passage_length  c      df      cf  \\\n",
      "0       19335  1017759       0  3.901871             309  3  270291  322485   \n",
      "1       19335  1082489       0  6.753509             494  2  270291  322485   \n",
      "2       19335   109063       0  6.547346             351  3  270291  322485   \n",
      "3       19335  1160863       0  4.193603             279  4  270291  322485   \n",
      "4       19335  1160871       0  4.209503             273  4  270291  322485   \n",
      "...       ...      ...     ...       ...             ... ..     ...     ...   \n",
      "9255  1133167  8839920       2  9.100336             252  5  649104  869667   \n",
      "9256  1133167  8839922       2  7.480691             250  3  649104  869667   \n",
      "9257  1133167   944810       0  2.127326             586  1  649104  869667   \n",
      "9258  1133167   949411       0  2.163620             577  1  649104  869667   \n",
      "9259  1133167   977421       0  6.752583             271  6  649104  869667   \n",
      "\n",
      "            idf       c_idf  \n",
      "0     15.600364   46.801093  \n",
      "1     15.600364   51.779880  \n",
      "2     15.600364  108.538546  \n",
      "3     15.600364   62.401457  \n",
      "4     15.600364   62.401457  \n",
      "...         ...         ...  \n",
      "9255   7.780719   54.639530  \n",
      "9256   7.780719   33.832780  \n",
      "9257   7.780719   13.026031  \n",
      "9258   7.780719   13.026031  \n",
      "9259   7.780719   46.684314  \n",
      "\n",
      "[9260 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transform data into dataframe\n",
    "testing_data = pd.DataFrame(testing_data, columns=['qid', 'docid', 'rating', 'bm25', 'passage_length', \\\n",
    "                                                   'c', 'df', 'cf', 'idf', 'c_idf'])\n",
    "# Save to csv in case the kernel is stopped during experiments\n",
    "testing_data.to_csv('testing_data.csv')\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9260/9260 [00:02<00:00, 3601.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Writing data to LETOR format\n",
    "with open('testing_data.txt', 'w') as file:\n",
    "    for index in tqdm(range(len(testing_data))):\n",
    "        row = testing_data.iloc[index]\n",
    "        file.write('{} qid:{} 1:{} 2:{} 3:{} 4:{} 5:{} 6:{} 7:{} # docid = {} \\n'.format(int(row['rating']), int(row['qid']), \\\n",
    "                                                                         row['bm25'], row['passage_length'], \\\n",
    "                                                                        row['c'], row['df'], row['cf'], \\\n",
    "                                                                        row['idf'], row['c_idf'], int(row['docid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "Creating the model:\n",
    "\n",
    "```\n",
    "java -jar RankLib-2.15.jar -train training_data.txt -ranker 8 -gmax 1 -validate validation_data.txt -test testing_data.txt -metric2T MAP -save RandomForests.txt\n",
    "```\n",
    "\n",
    "Result:\n",
    "```\n",
    "Discard orig. features\n",
    "Training data:\ttraining_data.txt\n",
    "Test data:\ttesting_data.txt\n",
    "Validation data:\tvalidation_data.txt\n",
    "Feature vector representation: Dense.\n",
    "Ranking method:\tRandom Forests\n",
    "Feature description file:\tUnspecified. All features will be used.\n",
    "Train metric:\tERR@10\n",
    "Test metric:\tMAP\n",
    "Highest relevance label (to compute ERR): 1\n",
    "Feature normalization: No\n",
    "Model file: RandomForests.txt\n",
    "\n",
    "[+] Random Forests's Parameters:\n",
    "No. of bags: 300\n",
    "Sub-sampling: 1.0\n",
    "Feature-sampling: 0.3\n",
    "No. of trees: 1\n",
    "No. of leaves: 100\n",
    "No. of threshold candidates: 256\n",
    "Learning rate: 0.1\n",
    "\n",
    "Reading feature file [training_data.txt]... [Done.]            \n",
    "(20000 ranked lists, 20000 entries read)\n",
    "Reading feature file [validation_data.txt]... [Done.]            \n",
    "(1998 ranked lists, 1999 entries read)\n",
    "Reading feature file [testing_data.txt]... [Done.]            \n",
    "(43 ranked lists, 9260 entries read)\n",
    "Initializing... [Done]\n",
    "------------------------------------\n",
    "Training starts...\n",
    "------------------------------------\n",
    "bag       | ERR@10-B  | ERR@10-OOB  | \n",
    "------------------------------------\n",
    "b[1]      | 0.2488    | \n",
    "b[2]      | 0.2457    | \n",
    "b[3]      | 0.2491    | \n",
    "b[4]      | 0.2486    | \n",
    "b[5]      | 0.2471    | \n",
    "b[6]      | 0.2515    | \n",
    "b[7]      | 0.2514    | \n",
    "b[8]      | 0.2506    | \n",
    "b[9]      | 0.2516    | \n",
    "b[10]     | 0.2473    | \n",
    "b[11]     | 0.2494    | \n",
    "b[12]     | 0.2504    | \n",
    "b[13]     | 0.2466    | \n",
    "b[14]     | 0.2505    | \n",
    "b[15]     | 0.2508    | \n",
    "b[16]     | 0.2515    | \n",
    "b[17]     | 0.2484    | \n",
    "b[18]     | 0.2501    | \n",
    "b[19]     | 0.2497    | \n",
    "b[20]     | 0.2468    | \n",
    "b[21]     | 0.2517    | \n",
    "b[22]     | 0.2518    | \n",
    "b[23]     | 0.2483    | \n",
    "b[24]     | 0.2525    | \n",
    "b[25]     | 0.2494    | \n",
    "b[26]     | 0.2527    | \n",
    "b[27]     | 0.2488    | \n",
    "b[28]     | 0.2498    | \n",
    "b[29]     | 0.252     | \n",
    "b[30]     | 0.2502    | \n",
    "b[31]     | 0.2516    | \n",
    "b[32]     | 0.2501    | \n",
    "b[33]     | 0.2485    | \n",
    "b[34]     | 0.2493    | \n",
    "b[35]     | 0.2473    | \n",
    "b[36]     | 0.2499    | \n",
    "b[37]     | 0.2471    | \n",
    "b[38]     | 0.2483    | \n",
    "b[39]     | 0.2528    | \n",
    "b[40]     | 0.2516    | \n",
    "b[41]     | 0.2488    | \n",
    "b[42]     | 0.2486    | \n",
    "b[43]     | 0.2517    | \n",
    "b[44]     | 0.2522    | \n",
    "b[45]     | 0.2503    | \n",
    "b[46]     | 0.2443    | \n",
    "b[47]     | 0.251     | \n",
    "b[48]     | 0.2494    | \n",
    "b[49]     | 0.2481    | \n",
    "b[50]     | 0.2503    | \n",
    "b[51]     | 0.2508    | \n",
    "b[52]     | 0.2511    | \n",
    "b[53]     | 0.2449    | \n",
    "b[54]     | 0.2464    | \n",
    "b[55]     | 0.2488    | \n",
    "b[56]     | 0.2491    | \n",
    "b[57]     | 0.2503    | \n",
    "b[58]     | 0.2484    | \n",
    "b[59]     | 0.2482    | \n",
    "b[60]     | 0.2485    | \n",
    "b[61]     | 0.2503    | \n",
    "b[62]     | 0.2505    | \n",
    "b[63]     | 0.2488    | \n",
    "b[64]     | 0.2522    | \n",
    "b[65]     | 0.2474    | \n",
    "b[66]     | 0.2473    | \n",
    "b[67]     | 0.2477    | \n",
    "b[68]     | 0.2477    | \n",
    "b[69]     | 0.2504    | \n",
    "b[70]     | 0.2482    | \n",
    "b[71]     | 0.2527    | \n",
    "b[72]     | 0.2515    | \n",
    "b[73]     | 0.2518    | \n",
    "b[74]     | 0.2507    | \n",
    "b[75]     | 0.2465    | \n",
    "b[76]     | 0.2484    | \n",
    "b[77]     | 0.2475    | \n",
    "b[78]     | 0.2507    | \n",
    "b[79]     | 0.2517    | \n",
    "b[80]     | 0.249     | \n",
    "b[81]     | 0.2493    | \n",
    "b[82]     | 0.2486    | \n",
    "b[83]     | 0.2521    | \n",
    "b[84]     | 0.252     | \n",
    "b[85]     | 0.2492    | \n",
    "b[86]     | 0.2518    | \n",
    "b[87]     | 0.2495    | \n",
    "b[88]     | 0.2483    | \n",
    "b[89]     | 0.2513    | \n",
    "b[90]     | 0.2507    | \n",
    "b[91]     | 0.2508    | \n",
    "b[92]     | 0.2509    | \n",
    "b[93]     | 0.2489    | \n",
    "b[94]     | 0.2505    | \n",
    "b[95]     | 0.249     | \n",
    "b[96]     | 0.2485    | \n",
    "b[97]     | 0.2512    | \n",
    "b[98]     | 0.2489    | \n",
    "b[99]     | 0.2484    | \n",
    "b[100]    | 0.2472    | \n",
    "b[101]    | 0.2514    | \n",
    "b[102]    | 0.2518    | \n",
    "b[103]    | 0.2501    | \n",
    "b[104]    | 0.2492    | \n",
    "b[105]    | 0.2524    | \n",
    "b[106]    | 0.2513    | \n",
    "b[107]    | 0.2495    | \n",
    "b[108]    | 0.2481    | \n",
    "b[109]    | 0.2512    | \n",
    "b[110]    | 0.2482    | \n",
    "b[111]    | 0.248     | \n",
    "b[112]    | 0.2479    | \n",
    "b[113]    | 0.2488    | \n",
    "b[114]    | 0.2492    | \n",
    "b[115]    | 0.2496    | \n",
    "b[116]    | 0.2519    | \n",
    "b[117]    | 0.2531    | \n",
    "b[118]    | 0.2516    | \n",
    "b[119]    | 0.2493    | \n",
    "b[120]    | 0.2503    | \n",
    "b[121]    | 0.2485    | \n",
    "b[122]    | 0.2482    | \n",
    "b[123]    | 0.2516    | \n",
    "b[124]    | 0.2474    | \n",
    "b[125]    | 0.2481    | \n",
    "b[126]    | 0.2508    | \n",
    "b[127]    | 0.2502    | \n",
    "b[128]    | 0.2491    | \n",
    "b[129]    | 0.248     | \n",
    "b[130]    | 0.2467    | \n",
    "b[131]    | 0.2522    | \n",
    "b[132]    | 0.2498    | \n",
    "b[133]    | 0.2496    | \n",
    "b[134]    | 0.2503    | \n",
    "b[135]    | 0.248     | \n",
    "b[136]    | 0.2504    | \n",
    "b[137]    | 0.2467    | \n",
    "b[138]    | 0.2536    | \n",
    "b[139]    | 0.2486    | \n",
    "b[140]    | 0.2494    | \n",
    "b[141]    | 0.249     | \n",
    "b[142]    | 0.249     | \n",
    "b[143]    | 0.2514    | \n",
    "b[144]    | 0.2507    | \n",
    "b[145]    | 0.2502    | \n",
    "b[146]    | 0.2496    | \n",
    "b[147]    | 0.2521    | \n",
    "b[148]    | 0.2502    | \n",
    "b[149]    | 0.2526    | \n",
    "b[150]    | 0.2535    | \n",
    "b[151]    | 0.2507    | \n",
    "b[152]    | 0.2483    | \n",
    "b[153]    | 0.2506    | \n",
    "b[154]    | 0.248     | \n",
    "b[155]    | 0.2534    | \n",
    "b[156]    | 0.2487    | \n",
    "b[157]    | 0.2539    | \n",
    "b[158]    | 0.2511    | \n",
    "b[159]    | 0.2528    | \n",
    "b[160]    | 0.2491    | \n",
    "b[161]    | 0.2485    | \n",
    "b[162]    | 0.2524    | \n",
    "b[163]    | 0.2471    | \n",
    "b[164]    | 0.2501    | \n",
    "b[165]    | 0.2509    | \n",
    "b[166]    | 0.2488    | \n",
    "b[167]    | 0.2511    | \n",
    "b[168]    | 0.2505    | \n",
    "b[169]    | 0.2502    | \n",
    "b[170]    | 0.2471    | \n",
    "b[171]    | 0.2468    | \n",
    "b[172]    | 0.2504    | \n",
    "b[173]    | 0.2509    | \n",
    "b[174]    | 0.2512    | \n",
    "b[175]    | 0.2486    | \n",
    "b[176]    | 0.25      | \n",
    "b[177]    | 0.2522    | \n",
    "b[178]    | 0.2512    | \n",
    "b[179]    | 0.2494    | \n",
    "b[180]    | 0.2536    | \n",
    "b[181]    | 0.2469    | \n",
    "b[182]    | 0.2531    | \n",
    "b[183]    | 0.2502    | \n",
    "b[184]    | 0.2523    | \n",
    "b[185]    | 0.2464    | \n",
    "b[186]    | 0.2497    | \n",
    "b[187]    | 0.2498    | \n",
    "b[188]    | 0.2502    | \n",
    "b[189]    | 0.2488    | \n",
    "b[190]    | 0.2505    | \n",
    "b[191]    | 0.2505    | \n",
    "b[192]    | 0.2477    | \n",
    "b[193]    | 0.2509    | \n",
    "b[194]    | 0.2512    | \n",
    "b[195]    | 0.2492    | \n",
    "b[196]    | 0.2493    | \n",
    "b[197]    | 0.2484    | \n",
    "b[198]    | 0.2495    | \n",
    "b[199]    | 0.249     | \n",
    "b[200]    | 0.25      | \n",
    "b[201]    | 0.2517    | \n",
    "b[202]    | 0.25      | \n",
    "b[203]    | 0.2493    | \n",
    "b[204]    | 0.2519    | \n",
    "b[205]    | 0.2505    | \n",
    "b[206]    | 0.2492    | \n",
    "b[207]    | 0.249     | \n",
    "b[208]    | 0.2475    | \n",
    "b[209]    | 0.2478    | \n",
    "b[210]    | 0.2511    | \n",
    "b[211]    | 0.2496    | \n",
    "b[212]    | 0.2501    | \n",
    "b[213]    | 0.2454    | \n",
    "b[214]    | 0.251     | \n",
    "b[215]    | 0.2492    | \n",
    "b[216]    | 0.2495    | \n",
    "b[217]    | 0.2517    | \n",
    "b[218]    | 0.2486    | \n",
    "b[219]    | 0.2531    | \n",
    "b[220]    | 0.2449    | \n",
    "b[221]    | 0.2465    | \n",
    "b[222]    | 0.2482    | \n",
    "b[223]    | 0.2514    | \n",
    "b[224]    | 0.2502    | \n",
    "b[225]    | 0.2477    | \n",
    "b[226]    | 0.2489    | \n",
    "b[227]    | 0.2511    | \n",
    "b[228]    | 0.2492    | \n",
    "b[229]    | 0.2499    | \n",
    "b[230]    | 0.2516    | \n",
    "b[231]    | 0.2523    | \n",
    "b[232]    | 0.2526    | \n",
    "b[233]    | 0.2465    | \n",
    "b[234]    | 0.2504    | \n",
    "b[235]    | 0.2502    | \n",
    "b[236]    | 0.2497    | \n",
    "b[237]    | 0.2472    | \n",
    "b[238]    | 0.2487    | \n",
    "b[239]    | 0.2479    | \n",
    "b[240]    | 0.2519    | \n",
    "b[241]    | 0.2476    | \n",
    "b[242]    | 0.2471    | \n",
    "b[243]    | 0.248     | \n",
    "b[244]    | 0.2478    | \n",
    "b[245]    | 0.2491    | \n",
    "b[246]    | 0.2506    | \n",
    "b[247]    | 0.2527    | \n",
    "b[248]    | 0.2494    | \n",
    "b[249]    | 0.2494    | \n",
    "b[250]    | 0.2485    | \n",
    "b[251]    | 0.2522    | \n",
    "b[252]    | 0.2494    | \n",
    "b[253]    | 0.2481    | \n",
    "b[254]    | 0.2486    | \n",
    "b[255]    | 0.2489    | \n",
    "b[256]    | 0.2482    | \n",
    "b[257]    | 0.254     | \n",
    "b[258]    | 0.2517    | \n",
    "b[259]    | 0.251     | \n",
    "b[260]    | 0.2486    | \n",
    "b[261]    | 0.253     | \n",
    "b[262]    | 0.2479    | \n",
    "b[263]    | 0.2476    | \n",
    "b[264]    | 0.2463    | \n",
    "b[265]    | 0.2493    | \n",
    "b[266]    | 0.2483    | \n",
    "b[267]    | 0.2519    | \n",
    "b[268]    | 0.2483    | \n",
    "b[269]    | 0.2489    | \n",
    "b[270]    | 0.2534    | \n",
    "b[271]    | 0.2489    | \n",
    "b[272]    | 0.2471    | \n",
    "b[273]    | 0.2495    | \n",
    "b[274]    | 0.2471    | \n",
    "b[275]    | 0.2498    | \n",
    "b[276]    | 0.2488    | \n",
    "b[277]    | 0.2477    | \n",
    "b[278]    | 0.2502    | \n",
    "b[279]    | 0.2501    | \n",
    "b[280]    | 0.2486    | \n",
    "b[281]    | 0.2499    | \n",
    "b[282]    | 0.2499    | \n",
    "b[283]    | 0.2498    | \n",
    "b[284]    | 0.2498    | \n",
    "b[285]    | 0.2484    | \n",
    "b[286]    | 0.2497    | \n",
    "b[287]    | 0.249     | \n",
    "b[288]    | 0.2486    | \n",
    "b[289]    | 0.2523    | \n",
    "b[290]    | 0.2486    | \n",
    "b[291]    | 0.2503    | \n",
    "b[292]    | 0.2537    | \n",
    "b[293]    | 0.2517    | \n",
    "b[294]    | 0.2509    | \n",
    "b[295]    | 0.2505    | \n",
    "b[296]    | 0.2504    | \n",
    "b[297]    | 0.2518    | \n",
    "b[298]    | 0.2519    | \n",
    "b[299]    | 0.249     | \n",
    "b[300]    | 0.2502    | \n",
    "------------------------------------\n",
    "Finished sucessfully.\n",
    "ERR@10 on training data: 0.25\n",
    "ERR@10 on validation data: 0.2503\n",
    "------------------------------------\n",
    "MAP on test data: 0.5371\n",
    "\n",
    "Model saved to: RandomForests.txt\n",
    "\n",
    "```\n",
    "\n",
    "Applying model to test data:\n",
    "\n",
    "```\n",
    "java -jar RankLib-2.15.jar -rank testing_data.txt -load RandomForests.txt -indri testoutputRF.trec\n",
    "```\n",
    "\n",
    "Result:\n",
    "\n",
    "```\n",
    "Discard orig. features\n",
    "Model file:\tRandomForests.txt\n",
    "Feature normalization: No\n",
    "Model:\t\tRandom Forests\n",
    "Reading feature file [testing_data.txt]... [Done.]            \n",
    "(43 ranked lists, 9260 entries read)\n",
    "```\n",
    "\n",
    "Evaluation results using trec_eval:\n",
    "\n",
    "```\n",
    "tools/eval/trec_eval.9.0.4/trec_eval -c -mrecall.1000 -mmap -mndcg -m ndcg_cut.5,10,100 -mP.10 -mgm_map -mrecip_rank.10  collections/msmarco-passage/2019qrels-pass.trec runs/testoutputRF.trec\n",
    "\n",
    "map                       all    0.5376\n",
    "gm_map                    all    0.4786\n",
    "recip_rank                all    0.7036\n",
    "P_10                      all    0.5163\n",
    "recall_1000               all    1.0000\n",
    "ndcg                      all    0.7392\n",
    "ndcg_cut_5                all    0.3840\n",
    "ndcg_cut_10               all    0.3830\n",
    "ndcg_cut_100              all    0.5820\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
